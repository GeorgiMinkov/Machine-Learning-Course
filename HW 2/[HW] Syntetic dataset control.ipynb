{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first will import needed libraries -> major one -> for dataset (make_moons),\n",
    "# for model (RandomForest, DecisionTree) and for interactive work (interactive)\n",
    "from sklearn.datasets import make_moons\n",
    "from ipywidgets import interactive\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot\n",
    "def plot_boundary(clf, X, y):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                         np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    ax.contourf(xx, yy, Z, alpha=0.4)\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor='k')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to control different dataset creation \n",
    "\n",
    "def moon_control(classification, samples, noise, random_state, num_trees, depth):\n",
    "    features, labels = make_moons(samples, noise=noise, random_state=random_state)\n",
    "    \n",
    "    if classification == 'DecisionTree':\n",
    "        classificator = DecisionTreeClassifier(max_depth=depth, random_state=random_state).fit(features, labels)\n",
    "        plot_boundary(classificator, features, labels)\n",
    "    else:\n",
    "        classificator = RandomForestClassifier(n_estimators=num_trees, max_depth=depth, random_state=random_state).fit(features, labels)\n",
    "        plot_boundary(classificator, features, labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def control(classificator, samples, noise, num_trees, depth): \n",
    "    world_peace_answer = 42\n",
    "    \n",
    "    moon_control(classificator, samples, noise, world_peace_answer, num_trees, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2844bc2468bb49538093d835994b1b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='classificator', options=('RandomForest', 'DecisionTree'), value='R…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive_plot = interactive(control, classificator=['RandomForest', 'DecisionTree'], \n",
    "                               samples=(1, 1000), noise=(0.01, 0.5), num_trees=(1, 100), depth=(1, 100))\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# from ipywidgets import interactive #\n",
    "# import matplotlib.pyplot as plt #\n",
    "# import numpy as np #\n",
    "\n",
    "# def f(m, b):\n",
    "#     plt.figure(2)\n",
    "#     x = np.linspace(-10, 10, num=1000)\n",
    "#     plt.plot(x, m * x + b)\n",
    "#     plt.ylim(-5, 5)\n",
    "#     plt.show()\n",
    "\n",
    "# interactive_plot = interactive(f, m=(-2.0, 2.0), b=(-3, 3, 0.5))\n",
    "# output = interactive_plot.children[-1]\n",
    "# output.layout.height = '350px'\n",
    "# interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# @interact(x = 1, y=fixed(10.0))\n",
    "# def g(x, y):\n",
    "#     return (x, y)\n",
    "# # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def f(x):\n",
    "#     print(x)\n",
    "\n",
    "# interact(f, x=widgets.IntSlider(min=-10,max=30,step=1,value=10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def plot_boundary(clf, X, y):\n",
    "#     x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "#     y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "#                          np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "#     f, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "#     Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "\n",
    "#     ax.contourf(xx, yy, Z, alpha=0.4)\n",
    "#     ax.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor='k')\n",
    "    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import eli5.sklearn.datasets.make_moons\n",
    "\n",
    "# def control(samples_):\n",
    "#     #CREATE DATASET\n",
    "#     X, y = make_moons(1500, noise=0.4, random_state=42)\n",
    "#     #SPLIT DATA\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "#     clf = RandomForestClassifier(random_state=23).fit(x_train, y_train) # без натройка на параметрите\n",
    "#     plot_boundary(clf, x, y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# clf = RandomForestClassifier(random_state=23).fit(x,y) # без натройка на параметрите\n",
    "# plot_boundary(clf, x, y)\n",
    "\n",
    "\n",
    "\n",
    "# #     n_estimators: брой дървета - 10, 100, 1000\n",
    "# #     criterion: за всички дървета - gini, entropy\n",
    "# #     max_features: Колко фичъра да се пробват при търсене на най-добро разделяне. sqrt(n_features) - различни при всяко ново търсене.\n",
    "# #     max_depth: Максимална дълбочина на дърветата\n",
    "# #     min_samples_split: Минимален брой семпли за да може да се раздели възела\n",
    "# #     bootstrap - Втори параметър за случайност - random sampling with replacement. Тегли същия брой семпли като оригиналния сет.\n",
    "# #     n_jobs - Тренира по няколко дървета едновременно, но използва повече памет.\n",
    "# #     random_state - възпроизведими експерименти\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
